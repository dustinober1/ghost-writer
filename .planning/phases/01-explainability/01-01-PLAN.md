---
phase: 01-explainability
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/ml/feature_extraction.py
  - backend/app/services/analysis_service.py
  - backend/app/api/routes/analysis.py
  - backend/app/models/schemas.py
  - frontend/src/components/HeatMap/HeatMap.tsx
autonomous: false
must_haves:
  truths:
    - "User can view per-sentence confidence scores with color-coded highlighting (high/medium/low risk)"
    - "Backend returns confidence level category (high/medium/low) for each sentence"
    - "Frontend displays confidence badge with visual indicator for each segment"
    - "User can hover/click segments to see detailed confidence information"
  artifacts:
    - path: "backend/app/models/schemas.py"
      provides: "ConfidenceLevel enum and extended TextSegment schema"
      contains: "class ConfidenceLevel"
    - path: "backend/app/services/analysis_service.py"
      provides: "Confidence level calculation per sentence"
      exports: ["_calculate_confidence_level"]
    - path: "frontend/src/components/HeatMap/HeatMap.tsx"
      provides: "Enhanced UI with confidence badges and improved visual hierarchy"
      min_lines: 450
  key_links:
    - from: "backend/app/services/analysis_service.py"
      to: "backend/app/models/schemas.py"
      via: "ConfidenceLevel enum import"
      pattern: "from.*models.*schemas.*import.*ConfidenceLevel"
    - from: "frontend/src/components/HeatMap/HeatMap.tsx"
      to: "/api/analysis"
      via: "Enhanced TextSegment response with confidence_level field"
      pattern: "confidence_level.*TextSegment"
---

<objective>
Enhance per-sentence confidence visualization with clear risk categorization and improved visual hierarchy.

Purpose: Users need immediate visual understanding of which sentences are flagged as AI-generated with three-tier risk system (high/medium/low) rather than just raw probability scores.

Output: Enhanced confidence scoring system with color-coded badges, improved tooltips, and accessible visual indicators.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md

@backend/app/ml/feature_extraction.py
@backend/app/services/analysis_service.py
@backend/app/api/routes/analysis.py
@backend/app/models/schemas.py
@frontend/src/components/HeatMap/HeatMap.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add confidence level categorization to backend</name>
  <files>backend/app/models/schemas.py, backend/app/services/analysis_service.py</files>
  <action>
    1. In backend/app/models/schemas.py:
       - Add ConfidenceLevel enum: HIGH (>0.7), MEDIUM (0.4-0.7), LOW (<0.4)
       - Extend TextSegment schema to include confidence_level field
       - Extend HeatMapData to include confidence_distribution stats

    2. In backend/app/services/analysis_service.py:
       - Add _calculate_confidence_level(probability: float) -> ConfidenceLevel method
       - Modify analyze_text() to assign confidence_level to each segment
       - Add confidence_distribution aggregation (count of high/medium/low)
       - Include confidence_level in segment_results dictionary

    DO NOT modify existing AI probability calculation logic - only add categorization layer on top.
  </action>
  <verify>
    Run: python -c "from backend.app.models.schemas import ConfidenceLevel; print('ConfidenceLevel enum imported successfully')"
    Check: TextSegment schema has confidence_level field with type ConfidenceLevel
  </verify>
  <done>
    - ConfidenceLevel enum defined with HIGH, MEDIUM, LOW values
    - TextSegment schema includes confidence_level field
    - analyze_text() returns confidence_level for each segment
    - HeatMapData includes confidence_distribution summary
  </done>
</task>

<task type="auto">
  <name>Task 2: Update API response to include confidence levels</name>
  <files>backend/app/api/routes/analysis.py</files>
  <action>
    Modify /api/analysis/analyze endpoint to:
    - Pass through confidence_level from analysis_service result
    - Include confidence_distribution in HeatMapData response
    - Update response model validation to ensure confidence_level is present

    Use existing AnalysisResponse structure - confidence_level flows through automatically via TextSegment schema update.
  </action>
  <verify>
    Run: curl -X POST http://localhost:8000/api/analysis/analyze -H "Content-Type: application/json" -d '{"text": "This is a test.", "granularity": "sentence"}' -H "Authorization: Bearer $TOKEN" | jq '.heat_map_data.segments[0].confidence_level'
    Expected: segments contain confidence_level field with value "HIGH", "MEDIUM", or "LOW"
  </verify>
  <done>
    - API returns confidence_level for each segment
    - API returns confidence_distribution in heat_map_data
    - Response model validation passes
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Backend confidence level system with API integration</what-built>
  <how-to-verify>
    1. Start backend server: docker-compose up backend
    2. Log in to application and navigate to /analyze
    3. Paste sample text and submit analysis
    4. Check browser DevTools Network tab for /api/analysis/analyze response
    5. Verify response includes:
       - segments[].confidence_level (HIGH/MEDIUM/LOW)
       - heat_map_data.confidence_distribution (counts for each level)

    Expected: Each segment has confidence_level field, distribution summary exists
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues with confidence level API response</resume-signal>
</task>

<task type="auto">
  <name>Task 3: Enhance frontend confidence visualization</name>
  <files>frontend/src/components/HeatMap/HeatMap.tsx</files>
  <action>
    Enhance HeatMap.tsx with confidence-aware visualization:

    1. Update TextSegment interface to include confidence_level: 'HIGH' | 'MEDIUM' | 'LOW'

    2. Add getConfidenceVariant(level) function:
       - HIGH -> 'error' (red theme)
       - MEDIUM -> 'warning' (yellow/orange theme)
       - LOW -> 'success' (green theme)

    3. Enhance segment rendering:
       - Add confidence badge overlay on each segment (small corner badge)
       - Improve color contrast for accessibility (WCAG AA compliant)
       - Add subtle border/stroke based on confidence level

    4. Update Segment Details sidebar:
       - Show confidence badge prominently (large, top of card)
       - Add confidence description text (e.g., "High AI likelihood - this sentence shows strong AI-generated patterns")
       - Color-code the entire card border based on confidence

    5. Enhance Statistics card:
       - Add confidence distribution breakdown (already calculated, now visualize)
       - Use donut chart or stacked bar for high/medium/low counts
       - Add percentage labels

    6. Improve tooltip on segment hover:
       - Show "AI Probability: XX% (HIGH/MEDIUM/LOW)"
       - Add quick interpretation text

    Maintain existing color gradient background - badges are ADDITIVE visual indicators.
  </action>
  <verify>
    Run: npm run build (frontend compiles without errors)
    Check: HeatMap.tsx has confidence_level handling in TextSegment interface
    Check: Badge components render with correct variants based on confidence level
  </verify>
  <done>
    - Confidence badges display on each segment (corner overlay)
    - Segment Details sidebar shows prominent confidence badge
    - Statistics card visualizes confidence distribution
    - Tooltips include confidence level text
    - Visual hierarchy is clear (confidence is primary information)
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete confidence visualization system</what-built>
  <how-to-verify>
    1. Start full application: docker-compose up
    2. Navigate to /analyze and submit text for analysis
    3. Verify on HeatMap results page:
       - Each sentence segment has small confidence badge overlay (H/M/L)
       - Color coding is clear: red=HIGH, yellow=MEDIUM, green=LOW
       - Click on a segment - sidebar shows large confidence badge
       - Statistics card shows distribution breakdown
       - Hovering over segments shows confidence in tooltip
       - Colors are readable and accessible (good contrast)

    4. Test with different texts:
       - All human text (mostly LOW badges)
       - Mixed text (variety of badges)
       - AI-generated text (mostly HIGH badges)

    Expected: Immediate visual understanding of risk levels without needing to read raw percentages
  </how-to-verify>
  <resume-signal>Type "approved" or describe UI/UX issues with confidence visualization</resume-signal>
</task>

</tasks>

<verification>
1. Backend returns confidence_level enum value for each sentence segment
2. Frontend displays confidence badges with clear color coding
3. User can distinguish high/medium/low risk segments at a glance
4. Clicking segments shows detailed confidence information in sidebar
5. Statistics show distribution of confidence levels across document
6. All visual elements pass accessibility contrast checks
</verification>

<success_criteria>
- [ ] ConfidenceLevel enum defined in schemas.py
- [ ] TextSegment includes confidence_level field
- [ ] analyze_text() assigns confidence level to each segment
- [ ] API response includes confidence_level for all segments
- [ ] Frontend displays confidence badges on segments
- [ ] Sidebar shows prominent confidence indicator
- [ ] Statistics card visualizes confidence distribution
- [ ] User can visually distinguish risk levels immediately
</success_criteria>

<output>
After completion, create `.planning/phases/01-explainability/01-01-SUMMARY.md`
</output>
