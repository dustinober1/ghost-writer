---
phase: 05-enhanced-fingerprinting
plan: 03
type: execute
wave: 2
depends_on: [05-01]
files_modified:
  - backend/app/ml/fingerprint/time_weighted_trainer.py
  - backend/app/ml/fingerprint/similarity_calculator.py
  - backend/app/ml/fingerprint/__init__.py
autonomous: true

must_haves:
  truths:
    - "System applies exponential moving average (EMA) with alpha=0.3 for time-weighted training"
    - "Recent writing samples receive higher weight in fingerprint calculation"
    - "Fingerprint includes per-feature statistics (mean, variance) for confidence intervals"
    - "Cosine similarity threshold of 0.70 used for 'likely match' classification"
    - "High similarity threshold of 0.85 for strong match classification"
  artifacts:
    - path: "backend/app/ml/fingerprint/time_weighted_trainer.py"
      provides: "TimeWeightedFingerprintBuilder class with EMA-based training"
      exports: ["TimeWeightedFingerprintBuilder", "add_sample", "get_fingerprint", "compute_recency_weights"]
      contains: "class TimeWeightedFingerprintBuilder"
    - path: "backend/app/ml/fingerprint/similarity_calculator.py"
      provides: "FingerprintComparator for similarity with confidence intervals"
      exports: ["FingerprintComparator", "compare_with_confidence", "THRESHOLD_HIGH_SIMILARITY"]
      contains: "class FingerprintComparator"
    - path: "backend/app/ml/fingerprint/__init__.py"
      provides: "Module exports for enhanced fingerprinting"
      exports: ["FingerprintCorpusBuilder", "TimeWeightedFingerprintBuilder", "FingerprintComparator"]
  key_links:
    - from: "backend/app/ml/fingerprint/time_weighted_trainer.py"
      to: "numpy"
      via: "np.array for vector operations, exponential decay calculation"
      pattern: "np\\.exp\\(-decay_rate \\* ages\\)"
    - from: "backend/app/ml/fingerprint/similarity_calculator.py"
      to: "sklearn.metrics.pairwise.cosine_similarity"
      via: "cosine_similarity import for similarity calculation"
      pattern: "cosine_similarity\\("
    - from: "backend/app/ml/fingerprint/time_weighted_trainer.py"
      to: "app.ml.feature_extraction.extract_feature_vector"
      via: "import for feature extraction"
      pattern: "from app.ml.feature_extraction import extract_feature_vector"
---

<objective>
Implement time-weighted fingerprint training and similarity calculation modules.

Purpose: Writing style evolves over time. Equal-weighted averaging treats all historical samples equally, causing fingerprints to become outdated. EMA gives recent samples higher weight while maintaining historical patterns. Confidence intervals quantify uncertainty in similarity scores.

Output: TimeWeightedFingerprintBuilder module, FingerprintComparator with confidence intervals, and module exports.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-enhanced-fingerprinting/05-enhanced-fingerprinting-RESEARCH.md

@.planning/phases/05-enhanced-fingerprinting/05-01-PLAN.md
@backend/app/ml/fingerprint/corpus_builder.py
@backend/app/ml/fingerprint.py
@backend/app/ml/feature_extraction.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement TimeWeightedFingerprintBuilder with EMA</name>
  <files>backend/app/ml/fingerprint/time_weighted_trainer.py</files>
  <action>
    Create backend/app/ml/fingerprint/time_weighted_trainer.py with:

    1. **TimeWeightedFingerprintBuilder** class:
       ```python
       class TimeWeightedFingerprintBuilder:
           MIN_SAMPLES_FOR_FINGERPRINT = 10

           def __init__(self, alpha: float = 0.3):
               """
               Args:
                   alpha: EMA smoothing factor (0-1). Higher = more weight to recent samples.
                          0.3 is standard for balanced recency.
               """
               self.alpha = alpha
               self.fingerprint_vector = None
               self.sample_count = 0
               self.feature_stats = {}  # Track per-feature statistics for CI
       ```

    2. **add_sample(self, features: np.ndarray, timestamp: datetime = None) -> None**:
       - If first sample: initialize fingerprint_vector = features.copy(), sample_count = 1
       - Otherwise: apply EMA update
         ```python
         self.fingerprint_vector = (
             (1 - self.alpha) * self.fingerprint_vector +
             self.alpha * features
         )
         self.sample_count += 1
         ```
       - Call _update_stats(features) to track per-feature mean/variance using Welford's algorithm

    3. **compute_recency_weights(self, timestamps: List[datetime], current_time: datetime) -> np.ndarray**:
       - Calculate age in days for each timestamp
       - Compute exponential decay weights: weight = e^(-lambda * age)
       - Lambda = -ln(alpha) for consistency with EMA
       - Normalize weights to sum to 1.0

    4. **get_fingerprint(self) -> Dict**:
       - Returns dictionary with:
         * feature_vector: list of floats
         * sample_count: int
         * model_version: "2.0"
         * method: "time_weighted_ema"
         * alpha: float
         * feature_statistics: dict from _get_feature_stats_summary()

    5. **_update_stats(self, features: np.ndarray) -> None**: Welford's online algorithm for variance
       ```python
       for i, val in enumerate(features):
           if i not in self.feature_stats:
               self.feature_stats[i] = {"mean": val, "variance": 0.0, "count": 1}
           else:
               stats = self.feature_stats[i]
               stats["count"] += 1
               delta = val - stats["mean"]
               stats["mean"] += delta / stats["count"]
               stats["variance"] += delta * (val - stats["mean"])
       ```

    6. **_get_feature_stats_summary(self) -> Dict**: Convert feature_stats to serializable format

    Imports: numpy as np, datetime from datetime, typing (List, Dict, Optional)
  </action>
  <verify>
    Run: python -c "from app.ml.fingerprint.time_weighted_trainer import TimeWeightedFingerprintBuilder; builder = TimeWeightedFingerprintBuilder(); print(f'alpha: {builder.alpha}')"
    Output: alpha: 0.3
  </verify>
  <done>
    Class initializes correctly, EMA formula implemented, Welford's algorithm tracks feature statistics
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement FingerprintComparator with confidence intervals</name>
  <files>backend/app/ml/fingerprint/similarity_calculator.py</files>
  <action>
    Create backend/app/ml/fingerprint/similarity_calculator.py with:

    1. **FingerprintComparator** class with class constants:
       ```python
       class FingerprintComparator:
           # Cosine similarity thresholds from authorship verification research
           THRESHOLD_HIGH_SIMILARITY = 0.85  # Strong match
           THRESHOLD_MEDIUM_SIMILARITY = 0.70  # Likely match
           THRESHOLD_LOW_SIMILARITY = 0.50  # Ambiguous/below threshold
       ```

    2. **__init__(self, confidence_level: float = 0.95)**:
       - Store confidence_level
       - Calculate z_score using scipy.stats.norm.ppf: self.z_score = stats.norm.ppf((1 + confidence_level) / 2)

    3. **compare_with_confidence(self, text_features: np.ndarray, fingerprint: Dict, fingerprint_stats: Dict = None) -> Dict**:
       - Extract fp_vector = np.array(fingerprint["feature_vector"])
       - Compute cosine similarity using sklearn.metrics.pairwise.cosine_similarity
       - Calculate CI width via _calculate_ci_width()
       - Compute feature deviations via _compute_feature_deviations()
       - Return dict with:
         * similarity: float (0-1)
         * confidence_interval: [lower, upper]
         * match_level: "HIGH" | "MEDIUM" | "LOW"
         * feature_deviations: dict of top 5 differing features

    4. **_calculate_ci_width(self, text_features, fp_vector, stats) -> float**:
       - If no stats: return 0.1 (default)
       - Extract variances from stats for each feature
       - Calculate SEM = sqrt(mean(variance) / n_features)
       - Return z_score * SEM

    5. **_classify_match(self, similarity: float) -> str**:
       - >= THRESHOLD_HIGH_SIMILARITY: return "HIGH"
       - >= THRESHOLD_MEDIUM_SIMILARITY: return "MEDIUM"
       - else: return "LOW"

    6. **_compute_feature_deviations(self, text_features, fp_vector, stats) -> Dict**:
       - For each feature, calculate absolute deviation
       - Normalize by sqrt(variance) if stats available
       - Return top 5 features by normalized deviation > 2.0
       - Format: {"feature_name": {"text_value": float, "fingerprint_value": float, "deviation": float}}

    Imports: numpy as np, scipy.stats, sklearn.metrics.pairwise.cosine_similarity
    Import FEATURE_NAMES from app.ml.feature_extraction
  </action>
  <verify>
    Run: python -c "from app.ml.fingerprint.similarity_calculator import FingerprintComparator; c = FingerprintComparator(); print(f'HIGH threshold: {c.THRESHOLD_HIGH_SIMILARITY}')"
    Output: HIGH threshold: 0.85
  </verify>
  <done>
    Comparator calculates cosine similarity, computes confidence intervals, classifies match level
  </done>
</task>

<task type="auto">
  <name>Task 3: Update fingerprint module exports</name>
  <files>backend/app/ml/fingerprint/__init__.py</files>
  <action>
    Create backend/app/ml/fingerprint/__init__.py with exports:

    ```python
    """
    Enhanced fingerprinting modules for corpus-based, time-weighted fingerprint generation.
    """
    from .corpus_builder import FingerprintCorpusBuilder
    from .time_weighted_trainer import TimeWeightedFingerprintBuilder
    from .similarity_calculator import FingerprintComparator

    # Legacy functions (for backward compatibility)
    from ..fingerprint import generate_fingerprint, update_fingerprint, compare_to_fingerprint

    __all__ = [
        "FingerprintCorpusBuilder",
        "TimeWeightedFingerprintBuilder",
        "FingerprintComparator",
        "generate_fingerprint",
        "update_fingerprint",
        "compare_to_fingerprint",
    ]
    ```

    This allows both new enhanced API and legacy single-sample API.
  </action>
  <verify>
    Run: python -c "from app.ml.fingerprint import FingerprintCorpusBuilder, TimeWeightedFingerprintBuilder, FingerprintComparator; print('Exports successful')"
  </verify>
  <done>
    All fingerprint modules can be imported from app.ml.fingerprint namespace
  </done>
</task>

</tasks>

<verification>
1. TimeWeightedFingerprintBuilder applies EMA correctly:
   - Test with 3 samples, verify recency weights increase for recent timestamps
2. FingerprintComparator returns correct similarity scores:
   - Test with identical text -> similarity >0.95
   - Test with very different text -> similarity <0.50
3. Module exports work:
   - from app.ml.fingerprint import TimeWeightedFingerprintBuilder, FingerprintComparator
</verification>

<success_criteria>
- Time-weighted training uses EMA with alpha=0.3, giving recent samples higher weight
- Fingerprint comparison returns similarity score with 95% confidence interval
- Match level classification uses thresholds: HIGH >=0.85, MEDIUM >=0.70, LOW <0.70
- Feature deviations highlight which stylometric features differ most
- All modules export correctly from app.ml.fingerprint namespace
</success_criteria>

<output>
After completion, create `.planning/phases/05-enhanced-fingerprinting/05-03-SUMMARY.md` with:
- EMA alpha value and recency calculation details
- Similarity threshold values and match level behavior
- Confidence interval calculation method (z-score, SEM)
- Any deviations from research recommendations
- Performance notes for similarity calculations
</output>
