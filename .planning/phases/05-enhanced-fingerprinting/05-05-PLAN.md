---
phase: 05-enhanced-fingerprinting
plan: 05
type: execute
wave: 3
depends_on: [05-03]
files_modified:
  - backend/app/models/database.py
  - backend/app/models/schemas.py
  - backend/app/ml/fingerprint/drift_detector.py
autonomous: true

must_haves:
  truths:
    - "DriftAlert database table stores alerts with severity, similarity_score, z_score, changed_features"
    - "StyleDriftDetector uses z-score based statistical process control for drift detection"
    - "Drift thresholds: warning >=2.0 std, alert >=3.0 std from baseline"
    - "DriftDetector establishes baseline from similarity scores and tracks sliding window"
    - "Schemas support drift detection requests and responses"
  artifacts:
    - path: "backend/app/models/database.py"
      provides: "DriftAlert table with severity, similarity_score, z_score, changed_features"
      contains: "class DriftAlert"
    - path: "backend/app/ml/fingerprint/drift_detector.py"
      provides: "StyleDriftDetector class with statistical process control"
      exports: ["StyleDriftDetector", "establish_baseline", "check_drift", "update_baseline"]
      contains: "class StyleDriftDetector"
    - path: "backend/app/models/schemas.py"
      provides: "DriftDetectionResult, DriftAlertResponse, DriftSeverity schemas"
  key_links:
    - from: "backend/app/ml/fingerprint/drift_detector.py"
      to: "FingerprintComparator"
      via: "similarity calculation for drift detection"
      pattern: "FingerprintComparator.*compare_with_confidence"
    - from: "backend/app/models/database.py"
      to: "DriftAlert table"
      via: "SQLAlchemy ORM model definition"
      pattern: "class DriftAlert"
    - from: "backend/app/ml/fingerprint/drift_detector.py"
      to: "numpy"
      via: "np.array for z-score calculation"
      pattern: "np\\.std|np\\.mean"
---

<objective>
Build drift detection backend infrastructure with database model and ML detector.

Purpose: Writing style evolves naturally, but sudden significant changes may indicate AI assistance or other influences. Statistical process control (z-score based drift detection) identifies significant deviations while accommodating gradual evolution. This plan establishes the database model and ML detector for drift detection.

Output: DriftAlert database table, StyleDriftDetector module, and drift detection schemas.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-enhanced-fingerprinting/05-enhanced-fingerprinting-RESEARCH.md

@.planning/phases/05-enhanced-fingerprinting/05-03-PLAN.md
@backend/app/ml/fingerprint/similarity_calculator.py
@backend/app/models/database.py
@backend/app/models/schemas.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create DriftAlert database model</name>
  <files>backend/app/models/database.py</files>
  <action>
    Add DriftAlert model to backend/app/models/database.py (after EnhancedFingerprint):

    ```python
    class DriftAlert(Base):
        """Style drift detection alerts."""
        __tablename__ = "drift_alerts"

        id = Column(Integer, primary_key=True, index=True)
        user_id = Column(Integer, ForeignKey("users.id"), nullable=False, index=True)
        fingerprint_id = Column(Integer, nullable=False)  # Reference to EnhancedFingerprint.id
        severity = Column(String, nullable=False, index=True)  # 'warning' or 'alert'
        similarity_score = Column(Float, nullable=False)  # Current similarity that triggered drift
        baseline_similarity = Column(Float, nullable=False)  # User's baseline average similarity
        z_score = Column(Float, nullable=False)  # Statistical distance from baseline
        changed_features = Column(JSON, nullable=True)  # Features that changed most
        text_preview = Column(String, nullable=True)  # First 200 chars of text that triggered
        acknowledged = Column(Boolean, default=False, nullable=False, index=True)
        created_at = Column(DateTime, default=datetime.utcnow, index=True)
    ```

    Add relationship to User model:
    ```python
    drift_alerts = relationship("DriftAlert", back_populates="user", cascade="all, delete-orphan")
    ```

    Add back_populates to DriftAlert:
    ```python
    user = relationship("User", back_populates="drift_alerts")
    ```

    No cascade on fingerprint_id to preserve alert history if fingerprint is regenerated.
  </action>
  <verify>
    Run: python -c "from app.models.database import DriftAlert; print('DriftAlert columns:', [c.name for c in DriftAlert.__table__.columns])"
    Verify: severity, similarity_score, z_score, changed_features, acknowledged columns exist
  </verify>
  <done>
    DriftAlert model compiles, all required columns defined, relationship to User established
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement StyleDriftDetector module</name>
  <files>backend/app/ml/fingerprint/drift_detector.py</files>
  <action>
    Create backend/app/ml/fingerprint/drift_detector.py with:

    1. **StyleDriftDetector** class:
       ```python
       class StyleDriftDetector:
           def __init__(
               self,
               window_size: int = 10,
               drift_threshold: float = 2.0,
               alert_threshold: float = 3.0
           ):
               """
               Args:
                   window_size: Number of recent samples to analyze
                   drift_threshold: Standard deviations for "warning" level (default 2.0)
                   alert_threshold: Standard deviations for "alert" level (default 3.0)
               """
       ```

    2. **Instance variables**:
       - self.window_size = window_size
       - self.drift_threshold = drift_threshold
       - self.alert_threshold = alert_threshold
       - self.similarity_window = deque(maxlen=window_size)  # Recent similarities
       - self.baseline_mean = None
       - self.baseline_std = None
       - self.baseline_established = False

    3. **establish_baseline(self, similarities: List[float]) -> None**:
       - Calculate baseline_mean = np.mean(similarities)
       - Calculate baseline_std = np.std(similarities)
       - Set baseline_established = True

    4. **check_drift(self, similarity: float, feature_deviations: Dict = None, timestamp: datetime = None) -> Dict**:
       - If not baseline_established: return {"drift_detected": False, "severity": "none", "reason": "baseline_not_established"}
       - Add similarity to sliding window
       - Calculate z_score = (baseline_mean - similarity) / baseline_std if std > 0 else 0
       - Determine severity:
         * abs(z_score) >= alert_threshold: "alert", drift_detected=True
         * abs(z_score) >= drift_threshold: "warning", drift_detected=True
         * else: "none", drift_detected=False
       - Calculate confidence_interval: [mean - threshold*std, mean + threshold*std]
       - Call _analyze_feature_changes(feature_deviations) for changed_features
       - Return dict with all fields

    5. **_analyze_feature_changes(self, feature_deviations: Dict) -> List[Dict]**:
       - If no deviations: return []
       - Return list of changes sorted by normalized_deviation DESC:
         ```python
         [
             {
                 "feature": feature_name,
                 "current_value": deviation_info["text_value"],
                 "baseline_value": deviation_info["fingerprint_value"],
                 "normalized_deviation": deviation_info["deviation"]
             }
         ]
         ```

    6. **update_baseline(self, new_similarities: List[float]) -> None**:
       - Combine window with new similarities
       - Recalculate mean and std
       - Use for when user acknowledges drift as legitimate style change

    Imports: numpy as np, datetime from datetime, typing (List, Dict, Optional), collections.deque
  </action>
  <verify>
    Run: python -c "from app.ml.fingerprint.drift_detector import StyleDriftDetector; d = StyleDriftDetector(); d.establish_baseline([0.8, 0.85, 0.82]); result = d.check_drift(0.5); print(f'drift_detected: {result[\"drift_detected\"]}')"
    Should detect drift with low similarity
  </verify>
  <done>
    Detector establishes baseline from similarities, identifies drift with z-score thresholds
  </done>
</task>

<task type="auto">
  <name>Task 3: Add drift detection schemas</name>
  <files>backend/app/models/schemas.py</files>
  <action>
    Add to backend/app/models/schemas.py (after FingerprintComparisonResponse, before Analysis Schemas):

    1. **DriftSeverity** enum:
       ```python
       class DriftSeverity(str, Enum):
           WARNING = "warning"
           ALERT = "alert"
           NONE = "none"
       ```

    2. **FeatureChange** (nested model):
       ```python
       class FeatureChange(BaseModel):
           feature: str
           current_value: float
           baseline_value: float
           normalized_deviation: float
       ```

    3. **DriftDetectionResult**:
       ```python
       class DriftDetectionResult(BaseModel):
           drift_detected: bool
           severity: DriftSeverity
           similarity: float
           baseline_mean: float
           z_score: float
           confidence_interval: List[float]  # [lower, upper]
           changed_features: List[FeatureChange]
           timestamp: Optional[datetime] = None
       ```

    4. **DriftAlertResponse**:
       ```python
       class DriftAlertResponse(BaseModel):
           id: int
           severity: DriftSeverity
           similarity_score: float
           baseline_similarity: float
           z_score: float
           changed_features: List[FeatureChange]
           text_preview: Optional[str] = None
           acknowledged: bool
           created_at: datetime

           class Config:
               from_attributes = True
       ```

    5. **DriftAlertsList**:
       ```python
       class DriftAlertsList(BaseModel):
           alerts: List[DriftAlertResponse]
           total: int
           unacknowledged_count: int
       ```

    Import Optional, List from typing, Enum from enum
  </action>
  <verify>
    Run: python -c "from app.models.schemas import DriftDetectionResult, DriftAlertResponse; print('Drift schemas imported')"
  </verify>
  <done>
    All drift-related schemas defined and validate correctly
  </done>
</task>

</tasks>

<verification>
1. DriftAlert model creates records with all required fields
2. StyleDriftDetector establishes baseline and identifies drift:
   - Test with baseline [0.8, 0.82, 0.85]
   - check_drift(0.95) should NOT trigger drift (too similar)
   - check_drift(0.50) should trigger ALERT (z-score > 3)
3. Schemas validate correctly with proper enum values
</verification>

<success_criteria>
- DriftAlert table stores alerts with severity, similarity_score, z_score, changed_features
- StyleDriftDetector uses z-score based statistical process control
- Drift thresholds: warning >=2.0 std, alert >=3.0 std from baseline
- Schemas support all drift detection operations
</success_criteria>

<output>
After completion, create `.planning/phases/05-enhanced-fingerprinting/05-05-SUMMARY.md` with:
- Database schema changes (DriftAlert table)
- StyleDriftDetector implementation details
- Z-score threshold values
- Any deviations from plan
</output>
