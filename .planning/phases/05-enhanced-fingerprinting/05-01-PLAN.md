---
phase: 05-enhanced-fingerprinting
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/models/database.py
  - backend/app/models/schemas.py
  - backend/app/ml/fingerprint/corpus_builder.py
autonomous: true

must_haves:
  truths:
    - "Database tables support storing individual writing samples with extracted features"
    - "EnhancedFingerprint table stores corpus-based fingerprints with metadata"
    - "Pydantic schemas validate corpus operations (add sample, status, generate)"
    - "FingerprintCorpusBuilder can aggregate 10+ samples with time-weighted averaging"
  artifacts:
    - path: "backend/app/models/database.py"
      provides: "FingerprintSample and EnhancedFingerprint tables"
      contains: "class FingerprintSample"
    - path: "backend/app/models/schemas.py"
      provides: "FingerprintSampleCreate, CorpusStatus, EnhancedFingerprintResponse schemas"
    - path: "backend/app/ml/fingerprint/corpus_builder.py"
      provides: "FingerprintCorpusBuilder class for multi-sample aggregation"
      exports: ["FingerprintCorpusBuilder", "add_sample", "build_fingerprint"]
      contains: "class FingerprintCorpusBuilder"
  key_links:
    - from: "backend/app/ml/fingerprint/corpus_builder.py"
      to: "backend/app/ml/feature_extraction.py"
      via: "extract_feature_vector import"
      pattern: "from app.ml.feature_extraction import extract_feature_vector"
    - from: "backend/app/models/database.py"
      to: "FingerprintSample table"
      via: "SQLAlchemy ORM model definition"
      pattern: "class FingerprintSample"
---

<objective>
Build corpus-based fingerprint data models and ML aggregation logic.

Purpose: Single-sample fingerprints lack statistical robustness. A multi-sample corpus provides feature variance tracking, supports time-weighted training, and enables confidence interval calculations. This plan establishes the database schema and ML aggregation foundation.

Output: Database tables for samples and enhanced fingerprints, Pydantic schemas, and corpus builder ML module.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-enhanced-fingerprinting/05-enhanced-fingerprinting-RESEARCH.md

@backend/app/ml/fingerprint.py
@backend/app/ml/feature_extraction.py
@backend/app/models/database.py
@backend/app/models/schemas.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create database models for corpus-based fingerprinting</name>
  <files>backend/app/models/database.py</files>
  <action>
    Add two new SQLAlchemy models to database.py:

    1. **FingerprintSample** - Stores individual writing samples with extracted features:
       - id (Integer, primary_key, index=True)
       - user_id (Integer, ForeignKey("users.id"), nullable=False, index=True)
       - text_content (Text, nullable=False) - Original text for reference
       - source_type (String, nullable=False) - 'email', 'essay', 'blog', 'academic', 'document', 'manual'
       - features (JSON, nullable=False) - 27-element stylometric feature array
       - word_count (Integer, nullable=False)
       - created_at (DateTime, default=datetime.utcnow, index=True)
       - written_at (DateTime, nullable=True) - When text was originally written (for time-weighting)
       - relationship: user = relationship("User", back_populates="fingerprint_samples")

    2. **EnhancedFingerprint** - Stores corpus-based fingerprint with metadata:
       - id (Integer, primary_key=True, index=True)
       - user_id (Integer, ForeignKey("users.id"), nullable=False, unique=True)
       - feature_vector (JSON, nullable=False) - 27-element averaged feature vector
       - feature_statistics (JSON, nullable=True) - Per-feature mean/std/variance for confidence intervals
       - corpus_size (Integer, default=0, nullable=False) - Number of samples used
       - method (String, default="time_weighted", nullable=False) - 'time_weighted', 'average', 'source_weighted'
       - alpha (Float, default=0.3, nullable=False) - EMA smoothing parameter
       - created_at (DateTime, default=datetime.utcnow)
       - updated_at (DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
       - source_distribution (JSON, nullable=True) - Count of samples by source_type
       - relationship: user = relationship("User", back_populates="enhanced_fingerprints")

    3. Add relationship to User model:
       - enhanced_fingerprints = relationship("EnhancedFingerprint", back_populates="user", cascade="all, delete-orphan")
       - fingerprint_samples = relationship("FingerprintSample", back_populates="user", cascade="all, delete-orphan")

    Use snake_case throughout. Import datetime from datetime module.
  </action>
  <verify>
    Run: python -c "from app.models.database import FingerprintSample, EnhancedFingerprint; print('Models imported successfully')"
    Verify: FingerprintSample has features JSON column, EnhancedFingerprint has feature_statistics JSON column
  </verify>
  <done>
    Database models compile without errors, all required columns and relationships defined
  </done>
</task>

<task type="auto">
  <name>Task 2: Add Pydantic schemas for corpus operations</name>
  <files>backend/app/models/schemas.py</files>
  <action>
    Add the following Pydantic schemas to schemas.py (after existing FingerprintStatus, before Analysis Schemas section):

    1. **FingerprintSampleCreate** - Request schema for adding samples:
       ```python
       class FingerprintSampleCreate(BaseModel):
           text_content: str = Field(..., min_length=10)
           source_type: str = Field(default="manual", pattern="^(email|essay|blog|academic|document|manual)$")
           written_at: Optional[datetime] = None
       ```

    2. **FingerprintSampleResponse** - Response schema for samples:
       ```python
       class FingerprintSampleResponse(BaseModel):
           id: int
           user_id: int
           source_type: str
           word_count: int
           created_at: datetime
           written_at: Optional[datetime] = None
           text_preview: str  # First 100 chars of text_content

           class Config:
               from_attributes = True
       ```

    3. **CorpusStatus** - Corpus summary response:
       ```python
       class CorpusStatus(BaseModel):
           sample_count: int
           total_words: int
           source_distribution: Dict[str, int]
           ready_for_fingerprint: bool
           samples_needed: int  # How many more samples needed (min 10)
           oldest_sample: Optional[datetime] = None
           newest_sample: Optional[datetime] = None
       ```

    4. **EnhancedFingerprintResponse** - Response for enhanced fingerprint:
       ```python
       class EnhancedFingerprintResponse(BaseModel):
           id: int
           user_id: int
           corpus_size: int
           method: str
           alpha: float
           source_distribution: Optional[Dict[str, int]] = None
           created_at: datetime
           updated_at: datetime

           class Config:
               from_attributes = True
       ```

    Add proper imports: Optional from typing, Dict, Field from pydantic.
  </action>
  <verify>
    Run: python -c "from app.models.schemas import FingerprintSampleCreate, CorpusStatus, EnhancedFingerprintResponse; print('Schemas imported successfully')"
  </verify>
  <done>
    All schemas validate correctly with pydantic, field constraints defined
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement FingerprintCorpusBuilder module</name>
  <files>backend/app/ml/fingerprint/corpus_builder.py</files>
  <action>
    Create new file backend/app/ml/fingerprint/__init__.py with: from .corpus_builder import FingerprintCorpusBuilder

    Create backend/app/ml/fingerprint/corpus_builder.py with:

    1. **FingerprintCorpusBuilder** class with methods:
       - __init__(self, min_samples: int = 10) - Initialize with minimum samples constant
       - add_sample(self, text: str, source_type: str = "manual", timestamp: Optional[datetime] = None) -> Dict
         * Validates text is not empty
         * Extracts features using extract_feature_vector(text)
         * Stores sample with metadata (features, timestamp, source_type, word_count, raw_features)
         * Returns sample metadata dictionary
       - build_fingerprint(self, method: str = "time_weighted", alpha: float = 0.3) -> Dict
         * Validates len(self.samples) >= MIN_SAMPLES_FOR_FINGERPRINT (10)
         * Sorts samples by timestamp
         * Calls _build_time_weighted(), _build_average(), or _build_source_weighted()
         * Returns fingerprint dict with feature_vector, sample_count, method, feature_statistics
       - get_corpus_summary(self) -> Dict with sample_count, total_words, source_distribution, ready_for_fingerprint

    2. **Time-weighted building** (_build_time_weighted method):
       - Iterate sorted_samples by timestamp
       - Apply EMA: new_vector = (1 - alpha) * old + alpha * new
       - Track feature statistics using Welford's online algorithm (mean, variance per feature)
       - Include corpus metadata: date_range (earliest/latest), source_distribution, average_word_count

    3. **Source-weighted building** (_build_source_weighted method):
       - Define source_weights: essay=1.2, academic=1.3, blog=1.0, email=0.9, document=1.1, manual=1.0
       - Compute weighted average using source weights

    4. **Constants**:
       - MIN_SAMPLES_FOR_FINGERPRINT = 10 (class attribute)
       - Import extract_feature_vector, FEATURE_NAMES from app.ml.feature_extraction

    Use numpy for vector operations. Handle edge cases: empty samples list, insufficient samples.
  </action>
  <verify>
    Run: python -c "from app.ml.fingerprint.corpus_builder import FingerprintCorpusBuilder; print('CorpusBuilder imported'); print(f'MIN_SAMPLES: {FingerprintCorpusBuilder.MIN_SAMPLES_FOR_FINGERPRINT}')"
  </verify>
  <done>
    Module imports successfully, MIN_SAMPLES constant accessible, class has required methods
  </done>
</task>

</tasks>

<verification>
1. Backend starts without errors: python -m app.main
2. Database tables created: FingerprintSample, EnhancedFingerprint
3. Pydantic schemas validate: FingerprintSampleCreate, CorpusStatus
4. CorpusBuilder imports: from app.ml.fingerprint.corpus_builder import FingerprintCorpusBuilder
5. MIN_SAMPLES constant equals 10
</verification>

<success_criteria>
- Database models support storing samples with features and enhanced fingerprints
- Pydantic schemas validate corpus operations
- FingerprintCorpusBuilder can aggregate samples with time-weighted averaging
- Minimum samples constant set to 10
</success_criteria>

<output>
After completion, create `.planning/phases/05-enhanced-fingerprinting/05-01-SUMMARY.md` with:
- Database schema changes (new tables)
- Schema definitions for corpus operations
- Corpus builder class structure
- Any deviations from plan
</output>
