---
phase: 03-enterprise-api
plan: 02
type: execute
wave: 2
depends_on: [03-01]
files_modified:
  - backend/app/middleware/rate_limit.py
  - backend/app/api/routes/api_usage.py
  - backend/app/main.py
autonomous: true

must_haves:
  truths:
    - "System enforces per-user rate limits based on subscription tier (free: 100/day, pro: 10000/day, enterprise: 100000/day)"
    - "Rate limit exceeded responses include X-RateLimit-Remaining, X-RateLimit-Limit, X-RateLimit-Reset headers"
    - "API key authentication triggers user-based rate limiting (not IP-based)"
    - "Rate limits tracked in Redis with automatic expiration using TTL"
    - "Developer can query current usage via GET /api/usage endpoint"
  artifacts:
    - path: "backend/app/middleware/rate_limit.py"
      provides: "TieredRateLimiter class with Redis-backed user-based limits"
      exports: ["TieredRateLimiter", "check_tiered_rate_limit"]
    - path: "backend/app/api/routes/api_usage.py"
      provides: "Usage metrics endpoint for quota tracking"
      exports: ["GET /api/usage"]
  key_links:
    - from: "backend/app/middleware/rate_limit.py"
      to: "redis"
      via: "redis.from_url(REDIS_URL)"
      pattern: "redis\\.from_url\\(REDIS_URL\\)"
    - from: "backend/app/middleware/rate_limit.py"
      to: "backend/app/models/database.py"
      via: "User.tier attribute read"
      pattern: "user\\.tier"
    - from: "backend/app/api/routes/api_usage.py"
      to: "backend/app/middleware/rate_limit.py"
      via: "get_usage_stats function"
      pattern: "get_usage_stats\\("
---

<objective>
Tiered Rate Limiting - System enforces per-user rate limits based on subscription tier with proper HTTP headers for quota visibility.

Purpose: Implement fair usage policies and prevent abuse while providing transparent quota information via HTTP headers. Tiered limits align with business model (free tier for evaluation, paid tiers for production use).

Output: Redis-backed rate limiting middleware, usage metrics endpoint, proper HTTP headers on rate-limited responses
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-enterprise-api/03-RESEARCH.md
@.planning/phases/03-enterprise-api/03-01-SUMMARY.md

@backend/app/middleware/rate_limit.py
@backend/app/utils/auth.py
@backend/app/models/database.py
@backend/app/main.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement tiered rate limiting middleware</name>
  <files>backend/app/middleware/rate_limit.py</files>
  <action>
    Completely replace the content of backend/app/middleware/rate_limit.py with tiered rate limiting:

    ```python
    """
    Tiered rate limiting middleware using Redis for user-based quota tracking.
    """
    from slowapi import Limiter
    from slowapi.util import get_remote_address
    from slowapi.errors import RateLimitExceeded
    from fastapi import Request, HTTPException, status
    from fastapi.responses import JSONResponse
    from sqlalchemy.orm import Session
    import os
    import redis
    import json
    from datetime import datetime, timedelta
    from typing import Optional, Dict, Any

    REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

    # Tier configuration: requests per day
    TIER_LIMITS = {
        "free": {"requests_per_day": 100, "requests_per_minute": 10},
        "pro": {"requests_per_day": 10000, "requests_per_minute": 100},
        "enterprise": {"requests_per_day": 100000, "requests_per_minute": 500},
    }

    # Initialize Redis client
    try:
        redis_client = redis.from_url(REDIS_URL, decode_responses=True)
        # Test connection
        redis_client.ping()
    except Exception:
        redis_client = None
        print("Warning: Redis not available, rate limiting will be degraded")


    def get_user_tier(user) -> str:
        """Get user's subscription tier from user.tier field"""
        if hasattr(user, 'tier') and user.tier:
            return user.tier
        return "free"


    def get_rate_limit_key(user_id: int, limit_type: str) -> str:
        """Generate Redis key for rate limit tracking"""
        now = datetime.utcnow()
        if limit_type == "day":
            # Use current date for daily key (resets at midnight UTC)
            date_key = now.strftime("%Y-%m-%d")
            return f"ratelimit:user:{user_id}:day:{date_key}"
        else:  # minute
            # Use current hour:minute for minute key
            minute_key = now.strftime("%Y-%m-%d:%H:%M")
            return f"ratelimit:user:{user_id}:min:{minute_key}"


    def check_rate_limit(user_id: int, tier: str) -> Dict[str, Any]:
        """
        Check and increment rate limits for a user.

        Returns dict with:
        - allowed: bool (whether request is allowed)
        - remaining_day: int (requests remaining today)
        - remaining_min: int (requests remaining this minute)
        - reset_time: str (ISO datetime when daily limit resets)
        - limit_day: int (daily limit)
        - limit_min: int (minute limit)
        """
        if not redis_client:
            # Redis unavailable - allow all (degraded mode)
            return {
                "allowed": True,
                "remaining_day": 9999,
                "remaining_min": 9999,
                "reset_time": (datetime.utcnow() + timedelta(days=1)).isoformat(),
                "limit_day": 9999,
                "limit_min": 9999
            }

        limits = TIER_LIMITS.get(tier, TIER_LIMITS["free"])
        day_key = get_rate_limit_key(user_id, "day")
        min_key = get_rate_limit_key(user_id, "minute")

        # Use Redis pipeline for atomic operations
        pipe = redis_client.pipeline()

        # Increment counters
        pipe.incr(day_key)
        pipe.incr(min_key)

        # Set expiration (daily key expires at end of day, minute key expires in 60s)
        # Calculate seconds until midnight UTC
        now = datetime.utcnow()
        midnight = (now + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
        seconds_until_midnight = int((midnight - now).total_seconds())

        pipe.expire(day_key, seconds_until_midnight)
        pipe.expire(min_key, 60)

        # Get current counts
        day_count = int(min(pipe.execute()[0], limits["requests_per_day"]))
        min_count = int(min(pipe.execute()[1], limits["requests_per_minute"]))

        remaining_day = max(0, limits["requests_per_day"] - day_count)
        remaining_min = max(0, limits["requests_per_minute"] - min_count)

        # Check if limits exceeded
        day_exceeded = day_count > limits["requests_per_day"]
        min_exceeded = min_count > limits["requests_per_minute"]

        if min_exceeded:
            return {
                "allowed": False,
                "remaining_day": remaining_day,
                "remaining_min": 0,
                "reset_time": (now + timedelta(seconds=60)).isoformat(),
                "limit_day": limits["requests_per_day"],
                "limit_min": limits["requests_per_minute"],
                "error": "minute_limit_exceeded"
            }

        if day_exceeded:
            return {
                "allowed": False,
                "remaining_day": 0,
                "remaining_min": remaining_min,
                "reset_time": midnight.isoformat(),
                "limit_day": limits["requests_per_day"],
                "limit_min": limits["requests_per_minute"],
                "error": "day_limit_exceeded"
            }

        return {
            "allowed": True,
            "remaining_day": remaining_day,
            "remaining_min": remaining_min,
            "reset_time": midnight.isoformat(),
            "limit_day": limits["requests_per_day"],
            "limit_min": limits["requests_per_minute"]
        }


    def add_rate_limit_headers(response: JSONResponse, rate_info: Dict[str, Any]):
        """Add rate limit headers to response"""
        response.headers["X-RateLimit-Limit-Day"] = str(rate_info["limit_day"])
        response.headers["X-RateLimit-Remaining-Day"] = str(rate_info["remaining_day"])
        response.headers["X-RateLimit-Limit-Minute"] = str(rate_info["limit_min"])
        response.headers["X-RateLimit-Remaining-Minute"] = str(rate_info["remaining_min"])
        response.headers["X-RateLimit-Reset"] = rate_info["reset_time"]
        return response


    class TieredRateLimiter:
        """Rate limiter that works with user-based authentication"""

        def __init__(self):
            self.redis_client = redis_client

        def check_request(self, request: Request, user_id: int, tier: str) -> Dict[str, Any]:
            """Check if request should be rate limited"""
            return check_rate_limit(user_id, tier)

        def get_usage_stats(self, user_id: int, tier: str) -> Dict[str, Any]:
            """Get current usage statistics for a user"""
            if not redis_client:
                return {
                    "tier": tier,
                    "limits": TIER_LIMITS.get(tier, TIER_LIMITS["free"]),
                    "usage": {"requests_today": 0, "requests_this_minute": 0},
                    "remaining": {"today": 0, "this_minute": 0}
                }

            limits = TIER_LIMITS.get(tier, TIER_LIMITS["free"])
            day_key = get_rate_limit_key(user_id, "day")
            min_key = get_rate_limit_key(user_id, "minute")

            day_count = int(redis_client.get(day_key) or 0)
            min_count = int(redis_client.get(min_key) or 0)

            return {
                "tier": tier,
                "limits": limits,
                "usage": {
                    "requests_today": day_count,
                    "requests_this_minute": min_count
                },
                "remaining": {
                    "today": max(0, limits["requests_per_day"] - day_count),
                    "this_minute": max(0, limits["requests_per_minute"] - min_count)
                }
            }


    # Global limiter instance
    tiered_limiter = TieredRateLimiter()


    # Maintain backward compatibility with existing SlowAPI limiter
    # for IP-based rate limiting on public endpoints
    limiter = Limiter(
        key_func=get_remote_address,
        storage_uri=REDIS_URL if redis_client else None,
        default_limits=["1000 per hour"]
    )


    def get_rate_limiter():
        """Get the rate limiter instance"""
        return limiter


    def get_tiered_rate_limiter():
        """Get the tiered rate limiter instance"""
        return tiered_limiter


    # Legacy rate limit decorators (for endpoints not using tiered limiting)
    auth_rate_limit = limiter.limit("5 per minute")
    analysis_rate_limit = limiter.limit("30 per minute")
    rewrite_rate_limit = limiter.limit("10 per minute")
    general_rate_limit = limiter.limit("100 per minute")


    def _rate_limit_exceeded_handler(request: Request, exc: RateLimitExceeded):
        """Handler for SlowAPI rate limit exceeded exceptions"""
        return JSONResponse(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            content={
                "detail": f"Rate limit exceeded: {exc.detail}"
            },
            headers={
                "Retry-After": "60"
            }
        )
    ```

    Key changes from existing:
    - Adds user-based (not IP-based) rate limiting
    - Uses Redis for distributed tracking
    - Adds TIER_LIMITS configuration
    - Tracks both daily and per-minute limits
    - Provides usage statistics
  </action>
  <verify>grep -n "class TieredRateLimiter" backend/app/middleware/rate_limit.py returns class definition</verify>
  <done>TieredRateLimiter class with Redis-backed user-based limits</done>
</task>

<task type="auto">
  <name>Task 2: Create usage metrics endpoint</name>
  <files>backend/app/api/routes/api_usage.py</files>
  <action>
    Create new file backend/app/api/routes/api_usage.py:

    ```python
    from fastapi import APIRouter, Depends, HTTPException, status
    from sqlalchemy.orm import Session
    from typing import Optional

    from app.models.database import get_db, User
    from app.utils.auth import get_current_user, get_api_key_user
    from app.middleware.rate_limit import get_tiered_rate_limiter

    router = APIRouter(prefix="/api", tags=["usage"])


    def get_current_user_for_api(
        token: Optional[str] = Depends(get_current_user),
        api_key_user: Optional[User] = Depends(get_api_key_user),
    ) -> User:
        """Get authenticated user from either JWT token or API key"""
        if token:
            return token
        if api_key_user:
            return api_key_user
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Authentication required"
        )


    @router.get("/usage")
    async def get_usage_metrics(
        current_user: User = Depends(get_current_user_for_api),
        db: Session = Depends(get_db)
    ):
        """
        Get current API usage metrics for the authenticated user.

        Returns:
        - Current tier
        - Rate limits for the tier
        - Usage statistics (requests today, this minute)
        - Remaining quota
        """
        # Get user's tier
        tier = current_user.tier if hasattr(current_user, 'tier') else "free"

        # Get usage stats from rate limiter
        limiter = get_tiered_rate_limiter()
        stats = limiter.get_usage_stats(current_user.id, tier)

        return stats


    @router.get("/limits")
    async def get_rate_limits(
        current_user: User = Depends(get_current_user_for_api),
    ):
        """
        Get rate limit information for the current user.

        Returns the rate limits that apply to the user's tier.
        """
        tier = current_user.tier if hasattr(current_user, 'tier') else "free"

        from app.middleware.rate_limit import TIER_LIMITS

        return {
            "tier": tier,
            "limits": TIER_LIMITS.get(tier, TIER_LIMITS["free"])
        }
    ```

    This endpoint supports both JWT and API key authentication.
  </action>
  <verify>grep -n "@router.get" backend/app/api/routes/api_usage.py returns endpoint definitions</verify>
  <done>GET /api/usage and GET /api/limits endpoints created</done>
</task>

<task type="auto">
  <name>Task 3: Wire usage router and apply rate limiting to analysis endpoints</name>
  <files>backend/app/main.py</files>
  <action>
    1. Import the api_usage router at the top:
    ```python
    from app.api.routes import auth, analysis, fingerprint, rewrite, analytics, account, admin, batch, api_keys, api_usage
    ```

    2. Include the router:
    ```python
    app.include_router(api_usage.router)
    ```

    3. Update the analysis router import to apply rate limiting - modify the import section and add rate limit dependency:
    ```python
    from app.middleware.rate_limit import tiered_limiter, check_rate_limit, add_rate_limit_headers
    from fastapi.responses import JSONResponse
    ```

    4. After including routers, add middleware for rate limit enforcement on protected endpoints:
    ```python
    @app.middleware("http")
    async def rate_limit_middleware(request: Request, call_next):
        \"\"\"Apply tiered rate limiting to authenticated requests\"\"\"
        # Skip rate limiting for health endpoints and public docs
        if request.url.path in ["/", "/health", "/ready", "/live", "/metrics", "/docs", "/redoc", "/openapi.json"]:
            return await call_next(request)

        # Skip rate limiting for auth endpoints (use IP-based limiting)
        if request.url.path.startswith("/api/auth/"):
            return await call_next(request)

        # Get user from header (token or API key)
        # For now, we'll add rate limit checks in individual endpoints
        # This middleware is for adding headers to responses
        response = await call_next(request)

        return response
    ```
  </action>
  <verify>grep "api_usage" backend/app/main.py returns import and include_router lines</verify>
  <done>api_usage router imported and included; rate limit middleware added</done>
</task>

<task type="auto">
  <name>Task 4: Apply rate limiting to analysis.py endpoints</name>
  <files>backend/app/api/routes/analysis.py</files>
  <action>
    Modify backend/app/api/routes/analysis.py to add tiered rate limiting:

    1. Add imports at top:
    ```python
    from app.middleware.rate_limit import check_rate_limit, add_rate_limit_headers, TIER_LIMITS
    from fastapi.responses import JSONResponse
    ```

    2. Update the /analyze endpoint to enforce rate limits:

    Find the analyze endpoint function and wrap the rate limit check at the start:
    ```python
    @router.post("/analyze")
    async def analyze_text(
        request: AnalysisRequest,
        current_user: User = Depends(get_current_user),
        db: Session = Depends(get_db)
    ):
        # Check rate limit
        tier = current_user.tier if hasattr(current_user, 'tier') else "free"
        rate_info = check_rate_limit(current_user.id, tier)

        if not rate_info["allowed"]:
            response = JSONResponse(
                status_code=429,
                content={
                    "detail": "Rate limit exceeded",
                    "error": rate_info.get("error", "day_limit_exceeded"),
                    "reset_time": rate_info["reset_time"]
                }
            )
            return add_rate_limit_headers(response, rate_info)

        # ... existing analysis logic ...

        # Add rate limit headers to successful response
        response_data = {
            # ... existing response ...
        }
        response = JSONResponse(content=response_data)
        return add_rate_limit_headers(response, rate_info)
    ```

    Apply similar pattern to batch upload endpoint in batch.py if needed.
  </action>
  <verify>grep -n "check_rate_limit" backend/app/api/routes/analysis.py returns rate limit check</verify>
  <done>Analysis endpoints enforce tiered rate limits with proper headers</done>
</task>

</tasks>

<verification>
1. Start Redis: `docker-compose up redis`
2. Restart backend: `docker-compose restart backend`
3. Test rate limit enforcement:
   ```bash
   # Get API key
   TOKEN=$(curl -X POST http://localhost:8000/api/auth/login-json \
     -H "Content-Type: application/json" \
     -d '{"email":"test@example.com","password":"testpass123"}' | jq -r '.access_token')

   KEY=$(curl -X POST http://localhost:8000/api/keys \
     -H "Authorization: Bearer $TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"name":"Test"}' | jq -r '.key')

   # Check usage (should show 0 used)
   curl http://localhost:8000/api/usage -H "X-API-Key: $KEY" | jq

   # Make analysis request and check rate limit headers
   curl -i http://localhost:8000/api/analysis/analyze \
     -H "X-API-Key: $KEY" \
     -H "Content-Type: application/json" \
     -d '{"text":"This is test text","granularity":"sentence"}' \
     | grep -i "X-RateLimit"
   ```
   Should see headers: X-RateLimit-Limit-Day, X-RateLimit-Remaining-Day, X-RateLimit-Reset

4. Test rate limit exceeded (lower tier for faster testing):
   ```bash
   # Modify user to free tier (100/day) and make rapid requests
   curl -v http://localhost:8000/api/analysis/analyze \
     -H "X-API-Key: $KEY" \
     -H "Content-Type: application/json" \
     -d '{"text":"test"}'
   ```
   After exceeding limits, should get 429 with proper headers
</verification>

<success_criteria>
1. TieredRateLimiter class tracks usage in Redis
2. Rate limits enforced per user (not IP)
3. GET /api/usage returns current usage statistics
4. Analysis endpoints return X-RateLimit-* headers
5. 429 responses include proper error detail and reset time
6. Daily limits reset at midnight UTC
7. Minute limits reset every 60 seconds
</success_criteria>

<output>
After completion, create `.planning/phases/03-enterprise-api/03-02-SUMMARY.md`
</output>
