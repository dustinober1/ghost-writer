---
phase: 02-batch-analysis
plan: 03
type: execute
wave: 3
depends_on: ["02-01", "02-02"]
files_modified:
  - backend/app/api/routes/batch.py
  - backend/app/services/batch_analysis_service.py
  - backend/app/tasks/analysis_tasks.py
  - backend/app/models/schemas.py
  - backend/app/api/routes/__init__.py
  - backend/app/main.py
  - backend/tests/test_batch_routes.py
  - frontend/src/services/api.ts
  - frontend/src/components/BatchAnalysis/BatchAnalysis.tsx
  - frontend/src/components/BatchAnalysis/BatchAnalysis.css
  - frontend/src/components/layout/Sidebar.tsx
  - frontend/src/App.tsx
  - frontend/src/components/BatchResults/BatchResults.tsx
  - frontend/src/components/BatchResults/BatchResults.css
  - frontend/src/components/ui/ProgressBar.tsx
autonomous: false
---

<objective>
Deliver batch upload, processing, results dashboard, and export capabilities with a calm overview-first UI.

Purpose: Let users analyze many documents at once, view clusters/similarity, and export results.
Output: Batch API endpoints, async processing via Celery, React batch upload/results views, and export links.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
@~/.config/opencode/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-batch-analysis/02-CONTEXT.md
@.planning/codebase/ARCHITECTURE.md
@.planning/codebase/CONVENTIONS.md
@.planning/codebase/STRUCTURE.md
@backend/app/api/routes/analysis.py
@backend/app/api/routes/fingerprint.py
@backend/app/tasks/analysis_tasks.py
@backend/app/services/analysis_service.py
@backend/app/models/schemas.py
@frontend/src/services/api.ts
@frontend/src/components/Dashboard/Dashboard.tsx
@frontend/src/components/layout/Sidebar.tsx
</context>

<tasks>
<task type="auto">
  <name>Task 1: Build batch analysis API and Celery task wiring</name>
  <files>backend/app/api/routes/batch.py, backend/app/services/batch_analysis_service.py, backend/app/tasks/analysis_tasks.py, backend/app/models/schemas.py, backend/app/api/routes/__init__.py, backend/app/main.py, backend/tests/test_batch_routes.py</files>
  <action>Create /api/batch routes: POST /upload (accept zip or multiple files), GET /{job_id}/status, GET /{job_id}/results, GET /{job_id}/export?format=csv|json. Use validate_upload_file and sanitize_text for each document. Store BatchAnalysisJob + BatchDocument records, enqueue Celery task to process documents (call AnalysisService.analyze_text for each doc, compute embeddings via get_ollama_embedding, then call BatchAnalysisService clustering + similarity). Update job progress fields and statuses. In export endpoints, return per-document rows with ai_probability, confidence_distribution, cluster_id, and overall job summary. Ensure route module is included in backend/app/api/routes/__init__.py and app.include_router. Add pytest coverage for upload + status + export endpoints with sqlite fixtures, mocking Celery delay to run synchronously. Avoid blocking requests for actual analysis; processing should be async.</action>
  <verify>cd backend && pytest tests/test_batch_routes.py</verify>
  <done>Batch upload creates a job, status shows progress, results include clusters/matrix, and export endpoints return CSV/JSON responses.</done>
</task>

<task type="auto">
  <name>Task 2: Implement batch upload and results UI</name>
  <files>frontend/src/services/api.ts, frontend/src/components/BatchAnalysis/BatchAnalysis.tsx, frontend/src/components/BatchAnalysis/BatchAnalysis.css, frontend/src/components/BatchResults/BatchResults.tsx, frontend/src/components/BatchResults/BatchResults.css, frontend/src/components/layout/Sidebar.tsx, frontend/src/App.tsx, frontend/src/components/ui/ProgressBar.tsx</files>
  <action>Add batchAPI helpers: uploadBatch(files/zip), getBatchStatus(jobId), getBatchResults(jobId), exportBatch(jobId, format). Create BatchAnalysis view with drag-drop + file picker + ZIP option, progress indicator, and job list. Create BatchResults view showing overview cards (documents, clusters, avg probability), cluster list, similarity heatmap grid (simple color scale), and per-document table. Use calm analytics styling consistent with Dashboard, reuse Card/Badge/ProgressBar. Add routes /batch and /batch/:jobId, and sidebar nav item. Avoid heavy visualization libs; use simple CSS grid for heatmap. Provide download buttons for CSV/JSON exports.</action>
  <verify>cd frontend && npm run build</verify>
  <done>Batch upload flow navigates to results, renders overview-first dashboard, and export buttons download files.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Batch analysis upload + overview-first results dashboard with clustering and similarity heatmap</what-built>
  <how-to-verify>
    1. Run: make up (or start backend/frontend manually)
    2. Visit: http://localhost:5173/batch
    3. Upload: 3-5 sample .txt files (or a zip) and submit
    4. Confirm: Progress indicator updates and status shows processing/completed
    5. After completion: Results page shows overview cards, clusters list, similarity matrix heatmap, and document table
    6. Click: Export CSV/JSON buttons download files
    7. Check: Layout is calm, readable, and not visually overwhelming
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues to fix</resume-signal>
</task>
</tasks>

<verification>
Before declaring plan complete:
- [ ] cd backend && pytest tests/test_batch_routes.py
- [ ] cd frontend && npm run build
</verification>

<success_criteria>
- Batch API supports upload, status, results, and export with async processing
- Clusters + similarity matrix are available in results payload
- Frontend provides overview-first dashboard and export actions
- Human verification confirms UX clarity and correct behavior
</success_criteria>

<output>
After completion, create `.planning/phases/02-batch-analysis/02-03-SUMMARY.md`
</output>
