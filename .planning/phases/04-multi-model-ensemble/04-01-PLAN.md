---
phase: 04-multi-model-ensemble
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/ml/ensemble/__init__.py
  - backend/app/ml/ensemble/ensemble_detector.py
  - backend/app/ml/ensemble/base_detectors.py
  - backend/app/ml/ensemble/weights.py
  - backend/app/services/analysis_service.py
  - backend/app/models/schemas.py
autonomous: true

must_haves:
  truths:
    - "System combines predictions from multiple detection models (stylometric, perplexity, contrastive)"
    - "Ensemble uses weighted soft voting based on individual model performance"
    - "Each model contributes to final AI probability score proportionally to its accuracy"
    - "Fallback to single model behavior if ensemble initialization fails"
  artifacts:
    - path: "backend/app/ml/ensemble/ensemble_detector.py"
      provides: "Main EnsembleDetector class with VotingClassifier"
      min_lines: 100
      exports: ["EnsembleDetector", "predict_ai_probability"]
    - path: "backend/app/ml/ensemble/base_detectors.py"
      provides: "Wrapper classes for stylometric, perplexity, and contrastive models"
      min_lines: 80
      exports: ["StylometricDetector", "PerplexityDetector", "ContrastiveDetectorWrapper"]
    - path: "backend/app/ml/ensemble/weights.py"
      provides: "Weight calculation based on model accuracy"
      min_lines: 40
      exports: ["calculate_weights_from_accuracy", "default_model_weights"]
  key_links:
    - from: "backend/app/services/analysis_service.py"
      to: "backend/app/ml/ensemble/ensemble_detector.py"
      via: "EnsembleDetector instantiation in AnalysisService.__init__"
      pattern: "EnsembleDetector\(\)"
    - from: "backend/app/ml/ensemble/base_detectors.py"
      to: "backend/app/ml/feature_extraction.py"
      via: "Import extract_feature_vector for stylometric features"
      pattern: "from app.ml.feature_extraction import"
    - from: "backend/app/ml/ensemble/base_detectors.py"
      to: "backend/app/ml/contrastive_model.py"
      via: "Import get_contrastive_model for Siamese network"
      pattern: "from app.ml.contrastive_model import"
---

<objective>
Implement multi-model ensemble orchestrator combining stylometric, perplexity, and contrastive detection models using sklearn's VotingClassifier with weighted soft voting for improved AI text detection accuracy.

Purpose: Single-model detection has limitations - ensemble methods combine diverse signals to reduce false positives and improve overall accuracy. Different models capture different aspects of AI-generated text (stylometric features, language model perplexity, semantic similarity).

Output: Working ensemble system that integrates three existing detection approaches, applies weighted voting, and provides calibrated AI probability scores.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/04-multi-model-ensemble/04-RESEARCH.md

@backend/app/ml/feature_extraction.py
@backend/app/ml/contrastive_model.py
@backend/app/services/analysis_service.py
@backend/app/models/schemas.py
</context>

<tasks>

<task type="auto">
  <name>Create ensemble detector with VotingClassifier</name>
  <files>backend/app/ml/ensemble/ensemble_detector.py</files>
  <action>
    Create backend/app/ml/ensemble/__init__.py with: from .ensemble_detector import EnsembleDetector

    Create backend/app/ml/ensemble/ensemble_detector.py with:

    1. EnsembleDetector class that wraps sklearn.ensemble.VotingClassifier
    2. __init__ method that:
       - Accepts optional model_accuracy dict for weight calculation
       - Initializes VotingClassifier with voting='soft', n_jobs=-1
       - Sets weights based on model accuracy (or defaults if not provided)
    3. predict_ai_probability(text: str) -> float method:
       - Extracts features from text using existing extract_feature_vector()
       - Gets predictions from all three base models
       - Combines using weighted soft voting
       - Returns final AI probability (0-1)
    4. _update_weights(model_accuracies: dict) method:
       - Calculates normalized weights from accuracy scores
       - Updates VotingClassifier weights parameter
    5. Graceful degradation: if sklearn not available or models fail, return stylometric-only result

    Use sklearn.ensemble.VotingClassifier with:
    - estimators: list of (name, estimator) tuples for three models
    - voting: 'soft' (use probabilities, not class labels)
    - weights: calculated from model accuracy or defaults [0.4, 0.3, 0.3]

    DO NOT create custom weighted averaging - use VotingClassifier which provides predict_proba(), cross-validation support, and sklearn integration.
  </action>
  <verify>
    python -c "from backend.app.ml.ensemble.ensemble_detector import EnsembleDetector; print('EnsembleDetector imported successfully')"
  </verify>
  <done>
    EnsembleDetector class exists with VotingClassifier, accepts text input, returns AI probability using weighted soft voting from three models
  </done>
</task>

<task type="auto">
  <name>Create base detector wrappers for ensemble integration</name>
  <files>backend/app/ml/ensemble/base_detectors.py</files>
  <action>
    Create backend/app/ml/ensemble/base_detectors.py with sklearn-compatible wrapper classes:

    1. StylometricDetector class:
       - Implements sklearn interface (fit(), predict_proba())
       - fit(X, y): stores training data shape, sets feature_dim
       - predict_proba(X): returns stylometric-based AI probabilities
       - Uses existing extract_feature_vector() from feature_extraction.py
       - Converts features to AI probability via inverse normalization

    2. PerplexityDetector class:
       - Implements sklearn interface
       - fit(X, y): stores calibration parameters
       - predict_proba(X): returns perplexity-based AI probabilities
       - Uses existing calculate_perplexity() from feature_extraction.py
       - Normalizes perplexity (50-100 range) to AI probability (0-1)

    3. ContrastiveDetectorWrapper class:
       - Implements sklearn interface
       - fit(X, y): initializes contrastive model
       - predict_proba(X): returns embedding-based AI probabilities
       - Uses existing get_contrastive_model() from contrastive_model.py
       - Maps similarity scores to AI probability (1 - similarity)

    Each wrapper must:
    - Accept numpy array input X for sklearn compatibility
    - Return shape (n_samples, 2) array for predict_proba() (class 0 and class 1 probabilities)
    - Handle edge cases (empty input, missing features)
    - Be serializable for future model persistence

    Import pattern:
    from app.ml.feature_extraction import extract_feature_vector, calculate_perplexity
    from app.ml.contrastive_model import get_contrastive_model
  </action>
  <verify>
    python -c "from backend.app.ml.ensemble.base_detectors import StylometricDetector, PerplexityDetector, ContrastiveDetectorWrapper; print('Base detectors imported')"
  </verify>
  <done>
    Three detector classes implemented with sklearn interface, each wraps existing detection logic, predict_proba() returns correct shape
  </done>
</task>

<task type="auto">
  <name>Implement weight calculation and integrate ensemble into analysis service</name>
  <files>backend/app/ml/ensemble/weights.py, backend/app/services/analysis_service.py, backend/app/models/schemas.py</files>
  <action>
    1. Create backend/app/ml/ensemble/weights.py:
       - calculate_weights_from_accuracy(model_accuracies: dict) -> list function
       - Normalizes accuracy values to sum to 1.0
       - Handles missing models with default weights
       - Returns list in order: [stylometric, perplexity, contrastive]

    2. Update backend/app/models/schemas.py:
       - Add EnsembleResult schema with fields:
         * stylometric_probability: float
         * perplexity_probability: float
         * contrastive_probability: float
         * ensemble_probability: float
         * model_weights: dict[str, float]
         * model_used: str ("ensemble" or "fallback")

    3. Update backend/app/services/analysis_service.py:
       - Import EnsembleDetector in __init__
       - Add self.ensemble_detector = EnsembleDetector() initialization
       - Create new method analyze_with_ensemble(text: str, granularity: str) -> dict
       - In analyze_text(), add ensemble_result field to each segment
       - Integrate ensemble probability as primary score (falling back to existing heuristics if unavailable)
       - Ensure backward compatibility: existing analyze_text() behavior preserved if ensemble disabled

    Integration approach:
    - Segment analysis calls ensemble.predict_ai_probability() for each segment
    - Result includes per-model probabilities AND ensemble result
    - Overall AI probability uses ensemble-weighted average
    - Graceful fallback: if ensemble unavailable, use existing _estimate_ai_probability()

    DO NOT break existing analyze_text() API - ensemble results are additive fields.
  </action>
  <verify>
    python -c "from backend.app.services.analysis_service import get_analysis_service; svc = get_analysis_service(); print(hasattr(svc, 'ensemble_detector'), 'Ensemble detector initialized')"
  </verify>
  <done>
    Weight calculation utility exists, analysis service integrates ensemble detector, analyze_with_ensemble() method returns per-model and ensemble probabilities, existing API unchanged
  </done>
</task>

</tasks>

<verification>
1. EnsembleDetector imports without errors
2. Base detector wrappers (StylometricDetector, PerplexityDetector, ContrastiveDetectorWrapper) implement sklearn interface
3. VotingClassifier configured with soft voting and weights
4. analyze_with_ensemble() returns EnsembleResult with all model probabilities
5. Existing analyze_text() still works (backward compatibility)
6. Graceful degradation when sklearn unavailable or models fail
</verification>

<success_criteria>
1. Three detection models (stylometric, perplexity, contrastive) contribute to final AI probability
2. Weighted soft voting implemented via sklearn VotingClassifier
3. Weights calculated from model accuracy or use sensible defaults
4. Per-segment ensemble results show individual model contributions
5. System degrades gracefully if ensemble unavailable
6. No breaking changes to existing analyze_text() API
</success_criteria>

<output>
After completion, create `.planning/phases/04-multi-model-ensemble/04-01-SUMMARY.md`
</output>
